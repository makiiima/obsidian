{"metadata": {"language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "Mindspore-python3.7-aarch64", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "## MindSpore-GCN-\u8bba\u6587\u5206\u7c7b\n### 1. \u4e0b\u8f7d\u6e90\u7801\u548c\u6570\u636e\u81f3\u672c\u5730\u5bb9\u5668\n\n\u56e0\u4e3anotebook\u662f\u6302\u8f7d\u5728obs\u4e0a\uff0c\u8fd0\u884c\u7684\u5bb9\u5668\u5b9e\u4f8b\u4e0d\u80fd\u76f4\u63a5\u8bfb\u53d6\u64cd\u4f5cobs\u4e0a\u7684\u6587\u4ef6\uff0c\u9700\u4e0b\u8f7d\u81f3\u5bb9\u5668\u672c\u5730\u73af\u5883\u4e2d", "metadata": {}}, {"cell_type": "code", "source": "import moxing as mox\nmox.file.copy_parallel(src_url=\"s3://ascend-zyjs-dcyang/nlp/gcn_mindspore_1.1/data/\", dst_url='./data/')  # \u5c06OBS\u6876\u4e2d\u6570\u636e\u62f7\u8d1d\u5230\u5bb9\u5668\u4e2d\nmox.file.copy_parallel(src_url=\"s3://ascend-zyjs-dcyang/nlp/gcn_mindspore_1.1/src/\", dst_url='./src/')\nmox.file.copy_parallel(src_url=\"s3://ascend-zyjs-dcyang/nlp/gcn_mindspore_1.1/graph_to_mindrecord/\", dst_url='./graph_to_mindrecord/')", "metadata": {"trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v1.17.3-d858ff4a\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "### 2. \u5bfc\u5165\u4f9d\u8d56\u5e93", "metadata": {}}, {"cell_type": "code", "source": "import os\n# os.environ['DEVICE_ID']='7'\n\nimport time\nimport argparse\nimport numpy as np\n\nfrom mindspore import nn\nfrom mindspore import Tensor\nfrom mindspore import context\nfrom mindspore.ops import operations as P\nfrom mindspore.nn.layer.activation import get_activation\nfrom easydict import EasyDict as edict\n\nfrom src.gcn import glorot, LossAccuracyWrapper, TrainNetWrapper\nfrom src.dataset import get_adj_features_labels, get_mask\nfrom graph_to_mindrecord.writer import run", "metadata": {"trusted": true}, "execution_count": 2, "outputs": [{"name": "stderr", "text": "[WARNING] ME(19704:281473886464304,MainProcess):2021-03-21-13:55:18.870.021 [mindspore/_check_version.py:207] MindSpore version 1.1.1 and \"te\" wheel package version 1.0 does not match, reference to the match info on: https://www.mindspore.cn/install\nMindSpore version 1.1.1 and \"topi\" wheel package version 0.6.0 does not match, reference to the match info on: https://www.mindspore.cn/install\n[WARNING] ME(19704:281473886464304,MainProcess):2021-03-21-13:55:19.470.887 [mindspore/ops/operations/array_ops.py:2302] WARN_DEPRECATED: The usage of Pack is deprecated. Please use Stack.\n", "output_type": "stream"}, {"name": "stdout", "text": "WARNING: 'ControlDepend' is deprecated from version 1.1 and will be removed in a future version, use 'Depend' instead.\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "context.set_context(mode=context.GRAPH_MODE,device_target=\"Ascend\", save_graphs=False)", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": "### 3. \u5b9a\u4e49\u53c2\u6570\u914d\u7f6e", "metadata": {}}, {"cell_type": "code", "source": "dataname = 'cora'\ndatadir_save = './data_mr'\ndatadir = os.path.join(datadir_save, dataname)\ncfg = edict({\n    'SRC_PATH': './data',\n    'MINDRECORD_PATH': datadir_save,\n    'DATASET_NAME': dataname,  # citeseer,cora\n    'mindrecord_partitions':1,\n    'mindrecord_header_size_by_bit' : 18,\n    'mindrecord_page_size_by_bit' : 20,\n\n    'data_dir': datadir,\n    'seed' : 123,\n    'train_nodes_num':140,\n    'eval_nodes_num':500,\n    'test_nodes_num':1000\n})", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "### 4. \u8f6c\u6362\u6570\u636e\u683c\u5f0f\u4e3amindrecord", "metadata": {}}, {"cell_type": "code", "source": "# \u8f6c\u6362\u6570\u636e\u683c\u5f0f\nprint(\"============== Graph To Mindrecord ==============\")\nrun(cfg)", "metadata": {"trusted": true}, "execution_count": 5, "outputs": [{"name": "stdout", "text": "============== Graph To Mindrecord ==============\nInit writer  ...\nexec task 0, parallel: False ...\nNode task is 0\ntransformed 512 record...\ntransformed 1024 record...\ntransformed 1536 record...\ntransformed 2048 record...\ntransformed 2560 record...\nProcessed 2708 lines for nodes.\ntransformed 2708 record...\nexec task 0, parallel: False ...\nEdge task is 0\ntransformed 512 record...\ntransformed 1024 record...\ntransformed 1536 record...\ntransformed 2048 record...\ntransformed 2560 record...\ntransformed 3072 record...\ntransformed 3584 record...\ntransformed 4096 record...\ntransformed 4608 record...\ntransformed 5120 record...\ntransformed 5632 record...\ntransformed 6144 record...\ntransformed 6656 record...\ntransformed 7168 record...\ntransformed 7680 record...\ntransformed 8192 record...\ntransformed 8704 record...\ntransformed 9216 record...\ntransformed 9728 record...\ntransformed 10240 record...\ntransformed 10752 record...\nProcessed 10858 lines for edges.\ntransformed 10858 record...\n--------------------------------------------\nEND. Total time: 7.293745756149292\n--------------------------------------------\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "### 5. \u5b9a\u4e49GCN\u7f51\u7edc\u53c2\u6570", "metadata": {}}, {"cell_type": "code", "source": "class ConfigGCN():\n    learning_rate = 0.01\n    epochs = 200\n    hidden1 = 16\n    dropout = 0.5\n    weight_decay = 5e-4\n    early_stopping = 10", "metadata": {"trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "markdown", "source": "### 6. \u5b9a\u4e49GCN\u7f51\u7edc\u7ed3\u6784", "metadata": {}}, {"cell_type": "code", "source": "class GraphConvolution(nn.Cell):\n    \"\"\"\n    GCN graph convolution layer.\n\n    Args:\n        feature_in_dim (int): The input feature dimension.\n        feature_out_dim (int): The output feature dimension.\n        dropout_ratio (float): Dropout ratio for the dropout layer. Default: None.\n        activation (str): Activation function applied to the output of the layer, eg. 'relu'. Default: None.\n\n    Inputs:\n        - **adj** (Tensor) - Tensor of shape :math:`(N, N)`.\n        - **input_feature** (Tensor) - Tensor of shape :math:`(N, C)`.\n\n    Outputs:\n        Tensor, output tensor.\n    \"\"\"\n\n    def __init__(self,\n                 feature_in_dim,\n                 feature_out_dim,\n                 dropout_ratio=None,\n                 activation=None):\n        super(GraphConvolution, self).__init__()\n        self.in_dim = feature_in_dim\n        self.out_dim = feature_out_dim\n        self.weight_init = glorot([self.out_dim, self.in_dim])\n        self.fc = nn.Dense(self.in_dim,\n                           self.out_dim,\n                           weight_init=self.weight_init,\n                           has_bias=False)\n        self.dropout_ratio = dropout_ratio\n        if self.dropout_ratio is not None:\n            self.dropout = nn.Dropout(keep_prob=1-self.dropout_ratio)\n        self.dropout_flag = self.dropout_ratio is not None\n        self.activation = get_activation(activation)\n        self.activation_flag = self.activation is not None\n        self.matmul = P.MatMul()\n\n    def construct(self, adj, input_feature):\n        dropout = input_feature\n        if self.dropout_flag:\n            dropout = self.dropout(dropout)\n\n        fc = self.fc(dropout)\n        output_feature = self.matmul(adj, fc)\n\n        if self.activation_flag:\n            output_feature = self.activation(output_feature)\n        return output_feature\n\n\nclass GCN(nn.Cell):\n    \"\"\"\n    GCN architecture.\n\n    Args:\n        config (ConfigGCN): Configuration for GCN.\n        adj (numpy.ndarray): Numbers of block in different layers.\n        feature (numpy.ndarray): Input channel in each layer.\n        output_dim (int): The number of output channels, equal to classes num.\n    \"\"\"\n\n    def __init__(self, config, adj, feature, output_dim):\n        super(GCN, self).__init__()\n        self.adj = Tensor(adj)\n        self.feature = Tensor(feature)\n        input_dim = feature.shape[1]\n        self.layer0 = GraphConvolution(input_dim, config.hidden1, activation=\"relu\", dropout_ratio=config.dropout)\n        self.layer1 = GraphConvolution(config.hidden1, output_dim, dropout_ratio=None)\n\n    def construct(self):\n        output0 = self.layer0(self.adj, self.feature)\n        output1 = self.layer1(self.adj, output0)\n        return output1", "metadata": {"trusted": true}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": "### 7. \u5b9a\u4e49\u8bad\u7ec3\u3001\u8bc4\u4f30\u51fd\u6570", "metadata": {}}, {"cell_type": "code", "source": "def train_eval(args_opt):\n    \"\"\"Train model.\"\"\"\n    np.random.seed(args_opt.seed)\n    config = ConfigGCN()\n    adj, feature, label = get_adj_features_labels(args_opt.data_dir)\n\n    nodes_num = label.shape[0]\n    train_mask = get_mask(nodes_num, 0, args_opt.train_nodes_num)\n    eval_mask = get_mask(nodes_num, args_opt.train_nodes_num, args_opt.train_nodes_num + args_opt.eval_nodes_num)\n    test_mask = get_mask(nodes_num, nodes_num - args_opt.test_nodes_num, nodes_num)\n\n    class_num = label.shape[1]\n    gcn_net = GCN(config, adj, feature, class_num)\n    gcn_net.add_flags_recursive(fp16=True)\n\n    eval_net = LossAccuracyWrapper(gcn_net, label, eval_mask, config.weight_decay)\n    test_net = LossAccuracyWrapper(gcn_net, label, test_mask, config.weight_decay)\n    train_net = TrainNetWrapper(gcn_net, label, train_mask, config)\n\n    loss_list = []\n    for epoch in range(config.epochs):\n        t = time.time()\n\n        train_net.set_train()\n        train_result = train_net()\n        train_loss = train_result[0].asnumpy()\n        train_accuracy = train_result[1].asnumpy()\n\n        eval_net.set_train(False)\n        eval_result = eval_net()\n        eval_loss = eval_result[0].asnumpy()\n        eval_accuracy = eval_result[1].asnumpy()\n\n        loss_list.append(eval_loss)\n        if epoch%10==0:\n            print(\"Epoch:\", '%04d' % (epoch), \"train_loss=\", \"{:.5f}\".format(train_loss),\n                \"train_acc=\", \"{:.5f}\".format(train_accuracy), \"val_loss=\", \"{:.5f}\".format(eval_loss),\n                \"val_acc=\", \"{:.5f}\".format(eval_accuracy), \"time=\", \"{:.5f}\".format(time.time() - t))\n\n        if epoch > config.early_stopping and loss_list[-1] > np.mean(loss_list[-(config.early_stopping+1):-1]):\n            print(\"Early stopping...\")\n            break\n\n    t_test = time.time()\n    test_net.set_train(False)\n    test_result = test_net()\n    test_loss = test_result[0].asnumpy()\n    test_accuracy = test_result[1].asnumpy()\n    print(\"Test set results:\", \"loss=\", \"{:.5f}\".format(test_loss),\n          \"accuracy=\", \"{:.5f}\".format(test_accuracy), \"time=\", \"{:.5f}\".format(time.time() - t_test))", "metadata": {"trusted": true}, "execution_count": 8, "outputs": []}, {"cell_type": "markdown", "source": "### 8. \u542f\u52a8\u8bad\u7ec3\u3001\u8bc4\u4f30", "metadata": {}}, {"cell_type": "code", "source": "#\u8bad\u7ec3\nprint(\"============== Starting Training ==============\")\ntrain_eval(cfg)", "metadata": {"trusted": true}, "execution_count": 9, "outputs": [{"name": "stdout", "text": "============== Starting Training ==============\nEpoch: 0000 train_loss= 1.95342 train_acc= 0.18571 val_loss= 1.94900 val_acc= 0.33000 time= 18.04168\nEpoch: 0010 train_loss= 1.86385 train_acc= 0.84286 val_loss= 1.90570 val_acc= 0.49800 time= 0.00300\nEpoch: 0020 train_loss= 1.74798 train_acc= 0.85000 val_loss= 1.86239 val_acc= 0.52000 time= 0.00274\nEpoch: 0030 train_loss= 1.60332 train_acc= 0.87857 val_loss= 1.80799 val_acc= 0.55800 time= 0.00272\nEpoch: 0040 train_loss= 1.44918 train_acc= 0.89286 val_loss= 1.74458 val_acc= 0.60400 time= 0.00270\nEpoch: 0050 train_loss= 1.30967 train_acc= 0.90000 val_loss= 1.67021 val_acc= 0.66400 time= 0.00270\nEpoch: 0060 train_loss= 1.16543 train_acc= 0.97143 val_loss= 1.59328 val_acc= 0.72200 time= 0.00270\nEpoch: 0070 train_loss= 1.02640 train_acc= 0.97857 val_loss= 1.52196 val_acc= 0.75800 time= 0.00272\nEpoch: 0080 train_loss= 0.92963 train_acc= 0.97857 val_loss= 1.45110 val_acc= 0.77200 time= 0.00271\nEpoch: 0090 train_loss= 0.87029 train_acc= 0.96429 val_loss= 1.38798 val_acc= 0.77400 time= 0.00271\nEpoch: 0100 train_loss= 0.80882 train_acc= 0.98571 val_loss= 1.33122 val_acc= 0.77800 time= 0.00270\nEpoch: 0110 train_loss= 0.76867 train_acc= 0.98571 val_loss= 1.29147 val_acc= 0.78200 time= 0.00270\nEpoch: 0120 train_loss= 0.68868 train_acc= 0.97857 val_loss= 1.25279 val_acc= 0.78200 time= 0.00270\nEpoch: 0130 train_loss= 0.66113 train_acc= 0.98571 val_loss= 1.21455 val_acc= 0.78200 time= 0.00271\nEpoch: 0140 train_loss= 0.65304 train_acc= 0.99286 val_loss= 1.18406 val_acc= 0.78000 time= 0.00270\nEpoch: 0150 train_loss= 0.60273 train_acc= 0.99286 val_loss= 1.16020 val_acc= 0.78200 time= 0.00273\nEpoch: 0160 train_loss= 0.59344 train_acc= 0.97857 val_loss= 1.12827 val_acc= 0.78200 time= 0.00271\nEpoch: 0170 train_loss= 0.57001 train_acc= 0.98571 val_loss= 1.11476 val_acc= 0.78600 time= 0.00271\nEpoch: 0180 train_loss= 0.53494 train_acc= 1.00000 val_loss= 1.09348 val_acc= 0.78600 time= 0.00270\nEpoch: 0190 train_loss= 0.51113 train_acc= 0.99286 val_loss= 1.07815 val_acc= 0.78400 time= 0.00271\nTest set results: loss= 1.01516 accuracy= 0.81200 time= 0.70676\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}]}